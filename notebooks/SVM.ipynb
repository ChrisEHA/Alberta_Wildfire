{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Version 2.0 - Support Vector Classifier\n",
    "    Data Source: European Space Agency - ERA5\n",
    "                 Government of Alberta - Historical Wildfire registry and Fire Weather Indices\n",
    "                 Natural Resources Canada - Vegetation Classification of Canada\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YKnxyxvjGoya"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Custom functions\n",
    "PROJECT_ROOT = '../'\n",
    "MODEL_PATH = os.path.join(PROJECT_ROOT,'models','SVM')\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "from scripts.data_utils import load_downsampled_df, load_full_df, get_train_validation_df, test_train_validation_split, extract_day_of_year\n",
    "from models.SVM.functions import SVM_preprocess_steps, SVM_predict\n",
    "\n",
    "# Other imports appear where needed. Specifically, imports joblib, numpy, and parts of sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y8xYsDLmGoyb"
   },
   "outputs": [],
   "source": [
    "## Test, Train, Validation Splits ##\n",
    "\n",
    "main_df = load_downsampled_df(PROJECT_ROOT)\n",
    "validation_df, test_train_df = get_train_validation_df(main_df)\n",
    "X_train, X_test, X_validation, y_train, y_test, y_validation = test_train_validation_split(validation_df,test_train_df)\n",
    "del main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w0I8B-Q8Goyd"
   },
   "outputs": [],
   "source": [
    "## Pipeline ##\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "\n",
    "date_transformer, feature_union = SVM_preprocess_steps()\n",
    "\n",
    "# Classifier\n",
    "SVM_clf = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    random_state=42,\n",
    "    C=10,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "SVM_pipeline = Pipeline([\n",
    "    ('day_of_year', date_transformer),\n",
    "    ('feature_union', feature_union),\n",
    "    ('classifier', SVM_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models\\\\SVM\\\\SVM_full_model.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train and save model ##\n",
    "from joblib import dump\n",
    "\n",
    "SVM_pipeline.fit(X_train,y_train)\n",
    "dump(SVM_pipeline,os.path.join(MODEL_PATH,'SVM_full_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models\\\\SVM\\\\SVM_model.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save model and preprocessing pipeline separately for ensemble models ##\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('day_of_year', SVM_pipeline.named_steps['day_of_year']),\n",
    "    ('feature_union', SVM_pipeline.named_steps['feature_union'])\n",
    "])\n",
    "\n",
    "dump(preprocessing_pipeline,os.path.join(MODEL_PATH,'SVM_preprocessing_pipeline.joblib'))\n",
    "dump(SVM_pipeline.named_steps['classifier'],os.path.join(MODEL_PATH,'SVM_model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.Visualization_functions import generate_visualizations, print_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the validation dataset\n",
    "main_df = load_full_df(PROJECT_ROOT)\n",
    "validation_df, test_train_df = get_train_validation_df(main_df)\n",
    "_, X_test, X_validation, _, y_test, y_validation = test_train_validation_split(validation_df,test_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pipeline\n",
    "from joblib import load\n",
    "\n",
    "SVM_pipeline = load(os.path.join(MODEL_PATH,'SVM_full_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CM and incorrect prediction heatmaps\n",
    "y_validation_pred = SVM_pipeline.predict(X_validation)\n",
    "generate_visualizations(X_validation,y_validation_pred,y_validation,main_df,os.path.join(MODEL_PATH,'SVM_Visuals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy: 0.9876643141081438\n",
      "f1 score:  0.1484883275928052\n",
      "Precision: 0.10424502955400322\n",
      "Recall: 0.2579787234042553\n"
     ]
    }
   ],
   "source": [
    "print_metrics(y_validation,y_validation_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation set predictions\n",
    "import numpy as np\n",
    "\n",
    "np.save(os.path.join(MODEL_PATH,'SVM_y_val_pred.npy'),y_validation_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Testing and Model Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n",
      "Best parameters: {'classifier__C': 15, 'classifier__gamma': 0.1}\n",
      "F1 Score: 74.25%\n"
     ]
    }
   ],
   "source": [
    "## Grid Search for Current Model ##\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#F1 scorer\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "\n",
    "# Parameters\n",
    "p_grid = {\"classifier__C\": [8, 10, 15],\n",
    "          \"classifier__gamma\": ['scale', 0.01, 0.1]\n",
    "}\n",
    "\n",
    "sv_classifier = SVC(kernel=\"rbf\",random_state=42)\n",
    "grid_search = GridSearchCV(SVM_pipeline, p_grid, cv=4, scoring=f1,n_jobs=-1,verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(f\"F1 Score: {100*grid_search.best_score_:.2f}%\")\n",
    "\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fitting 4 folds for each of 9 candidates, totalling 36 fits\n",
    "# Best parameters: {'C': 10, 'gamma': 0.1}\n",
    "# F1 Score: 74.14%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
