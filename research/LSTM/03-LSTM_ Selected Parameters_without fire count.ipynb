{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for random forest training by Raymond Xu.\n",
    "\n",
    " In this edition, the longitude and latitude of the original wildfire dataset is used as inputs.\n",
    "\n",
    " Here the temporal sequence is not considered in the data splitting.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This is Research Project titled ML Algorithms for Alberta Forest Occurence Prediction.\\n    This is the 8th Engineering Research Project, and is hereby delcared as\\n                            \\n                            Project Christopher\\n    \\n    Version 1.0 - Long Short-Term Memory Classifier\\n    Data Source: European Space Agency - ERA5\\n                 Government of Alberta - Historical Wildfire registry and Fire Weather Indices\\n                 Natural Resources Canada - Vegetation Classification of Canada\\n    \\n    AI Diederik - Hongik Ingan, For the Benefits of All Mankind\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' This is Research Project titled ML Algorithms for Alberta Forest Occurence Prediction.\n",
    "    This is the 8th Engineering Research Project, and is hereby delcared as\n",
    "                            \n",
    "                            Project Christopher\n",
    "    \n",
    "    Version 1.0 - Long Short-Term Memory Classifier\n",
    "    Data Source: European Space Agency - ERA5\n",
    "                 Government of Alberta - Historical Wildfire registry and Fire Weather Indices\n",
    "                 Natural Resources Canada - Vegetation Classification of Canada\n",
    "    \n",
    "    AI Diederik - Hongik Ingan, For the Benefits of All Mankind\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_df['month'] = validation_df['date'].dt.month\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_df['year'] = validation_df['date'].dt.year\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_train_df['month'] = test_train_df['date'].dt.month\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_train_df['year'] = test_train_df['date'].dt.year\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by='month', inplace=True,ascending=True)\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[df['month'] == month].sort_values(by='year', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load wildfire and non-wildfire datasets\n",
    "def load_downsampled_df():\n",
    "    main_df = pd.read_csv(\"D:/Shared drives/MECE 788 - Forest Fire Prediction/04_Preprocessing/Cleanup_and_point_selection/downsampled_df.csv\",index_col=0)\n",
    "    main_df['date'] = pd.to_datetime(main_df['date'])\n",
    "    return main_df\n",
    "\n",
    "\n",
    "main_df = load_downsampled_df()\n",
    "\n",
    "# Create the validation dataframe out of data after 2019\n",
    "validation_df = main_df[main_df['date'] > pd.Timestamp('2019-01-01')]\n",
    "test_train_df = main_df[main_df['date'] < pd.Timestamp('2019-01-01')]\n",
    "\n",
    "def En_test_train_validation_split(validation_df, test_train_df, target_variable='fire', test_proportion=0.33):\n",
    "    \"\"\"\n",
    "    Validation data is obtained by taking all data after a certain time. This is similar to model deployment.\n",
    "    Train and test data are obtained using a stratified split\n",
    "    \"\"\"    \n",
    "    # Step 1: Sort data by month, then by year within each month\n",
    "    validation_df['month'] = validation_df['date'].dt.month\n",
    "    validation_df['year'] = validation_df['date'].dt.year\n",
    "\n",
    "    split_index = int(len(test_train_df) * (1 - test_proportion))\n",
    "    test_train_df['month'] = test_train_df['date'].dt.month\n",
    "    test_train_df['year'] = test_train_df['date'].dt.year\n",
    "\n",
    "    for df in [validation_df,test_train_df]:\n",
    "        # Sort by month\n",
    "        df.sort_values(by='month', inplace=True,ascending=True)\n",
    "        # Sort by year within each month\n",
    "        for month in df['month'].unique():\n",
    "            df.loc[df['month'] == month].sort_values(by='year', inplace=True)\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    train_df = test_train_df[test_train_df['date'] < pd.Timestamp('2013-01-01')]\n",
    "    test_df = test_train_df[test_train_df['date'] > pd.Timestamp('2013-01-01')]\n",
    "\n",
    "    # Split the test and training\n",
    "    y_test=test_df['fire']\n",
    "    y_train=train_df['fire']\n",
    "    y_validation=validation_df['fire']\n",
    "    X_test=test_df.drop(columns=['fire'])\n",
    "    X_train=train_df.drop(columns=['fire'])\n",
    "    X_validation=validation_df.drop(columns=['fire'])\n",
    "    \n",
    "    return X_train, X_test, X_validation, y_train, y_test, y_validation\n",
    "\n",
    "# Get the splits\n",
    "X_train, X_test, X_validation, y_train, y_test, y_validation = En_test_train_validation_split(validation_df, test_train_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>high_vegetation_cover</th>\n",
       "      <th>leaf_area_index_high_vegetation</th>\n",
       "      <th>leaf_area_index_low_vegetation</th>\n",
       "      <th>low_vegetation_cover</th>\n",
       "      <th>slope_of_sub_gridscale_orography</th>\n",
       "      <th>type_of_high_vegetation</th>\n",
       "      <th>type_of_low_vegetation</th>\n",
       "      <th>...</th>\n",
       "      <th>fire_count_past_3Days</th>\n",
       "      <th>fire_count_past_7Days</th>\n",
       "      <th>fire_count_past_10Days</th>\n",
       "      <th>fire_count_past_30Days</th>\n",
       "      <th>24hr_max_temperature_1dayLag</th>\n",
       "      <th>24hr_max_temperature_2dayLag</th>\n",
       "      <th>global_noon_LST_2m_temperature_1dayLag</th>\n",
       "      <th>global_noon_LST_2m_temperature_2dayLag</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104032</th>\n",
       "      <td>2005-03-13</td>\n",
       "      <td>54.50</td>\n",
       "      <td>242.75</td>\n",
       "      <td>0.998321</td>\n",
       "      <td>1.417741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.699545</td>\n",
       "      <td>14.356647</td>\n",
       "      <td>4.760975</td>\n",
       "      <td>11.200683</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104005</th>\n",
       "      <td>2005-03-08</td>\n",
       "      <td>54.25</td>\n",
       "      <td>245.25</td>\n",
       "      <td>0.977950</td>\n",
       "      <td>0.839266</td>\n",
       "      <td>2.777072</td>\n",
       "      <td>0.022050</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.398298</td>\n",
       "      <td>13.631983</td>\n",
       "      <td>1.314445</td>\n",
       "      <td>5.868976</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104031</th>\n",
       "      <td>2005-03-13</td>\n",
       "      <td>49.50</td>\n",
       "      <td>246.00</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>1.510647</td>\n",
       "      <td>2.051366</td>\n",
       "      <td>0.099629</td>\n",
       "      <td>0.018694</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.594701</td>\n",
       "      <td>13.136620</td>\n",
       "      <td>1.773049</td>\n",
       "      <td>11.612025</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104004</th>\n",
       "      <td>2005-03-07</td>\n",
       "      <td>54.50</td>\n",
       "      <td>245.50</td>\n",
       "      <td>0.691179</td>\n",
       "      <td>0.829118</td>\n",
       "      <td>2.786724</td>\n",
       "      <td>0.308822</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.731755</td>\n",
       "      <td>12.660513</td>\n",
       "      <td>6.087775</td>\n",
       "      <td>9.173723</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104002</th>\n",
       "      <td>2005-03-07</td>\n",
       "      <td>54.25</td>\n",
       "      <td>245.50</td>\n",
       "      <td>0.691179</td>\n",
       "      <td>1.076542</td>\n",
       "      <td>2.458123</td>\n",
       "      <td>0.308822</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.526958</td>\n",
       "      <td>12.282427</td>\n",
       "      <td>5.821715</td>\n",
       "      <td>8.732624</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  latitude  longitude  high_vegetation_cover  \\\n",
       "104032 2005-03-13     54.50     242.75               0.998321   \n",
       "104005 2005-03-08     54.25     245.25               0.977950   \n",
       "104031 2005-03-13     49.50     246.00               0.900371   \n",
       "104004 2005-03-07     54.50     245.50               0.691179   \n",
       "104002 2005-03-07     54.25     245.50               0.691179   \n",
       "\n",
       "        leaf_area_index_high_vegetation  leaf_area_index_low_vegetation  \\\n",
       "104032                         1.417741                        0.000000   \n",
       "104005                         0.839266                        2.777072   \n",
       "104031                         1.510647                        2.051366   \n",
       "104004                         0.829118                        2.786724   \n",
       "104002                         1.076542                        2.458123   \n",
       "\n",
       "        low_vegetation_cover  slope_of_sub_gridscale_orography  \\\n",
       "104032              0.001556                          0.006706   \n",
       "104005              0.022050                          0.004886   \n",
       "104031              0.099629                          0.018694   \n",
       "104004              0.308822                          0.004543   \n",
       "104002              0.308822                          0.004506   \n",
       "\n",
       "        type_of_high_vegetation  type_of_low_vegetation  ...  \\\n",
       "104032                        2                       0  ...   \n",
       "104005                       19                       1  ...   \n",
       "104031                        2                       2  ...   \n",
       "104004                       19                       1  ...   \n",
       "104002                       19                       1  ...   \n",
       "\n",
       "        fire_count_past_3Days  fire_count_past_7Days  fire_count_past_10Days  \\\n",
       "104032                    0.0                    0.0                     0.0   \n",
       "104005                    0.0                    0.0                     0.0   \n",
       "104031                    0.0                    0.0                     0.0   \n",
       "104004                    0.0                    0.0                     0.0   \n",
       "104002                    0.0                    0.0                     0.0   \n",
       "\n",
       "        fire_count_past_30Days  24hr_max_temperature_1dayLag  \\\n",
       "104032                     0.0                     11.699545   \n",
       "104005                     0.0                      8.398298   \n",
       "104031                     0.0                     14.594701   \n",
       "104004                     0.0                     13.731755   \n",
       "104002                     0.0                     13.526958   \n",
       "\n",
       "        24hr_max_temperature_2dayLag  global_noon_LST_2m_temperature_1dayLag  \\\n",
       "104032                     14.356647                                4.760975   \n",
       "104005                     13.631983                                1.314445   \n",
       "104031                     13.136620                                1.773049   \n",
       "104004                     12.660513                                6.087775   \n",
       "104002                     12.282427                                5.821715   \n",
       "\n",
       "        global_noon_LST_2m_temperature_2dayLag  month  year  \n",
       "104032                               11.200683      3  2005  \n",
       "104005                                5.868976      3  2005  \n",
       "104031                               11.612025      3  2005  \n",
       "104004                                9.173723      3  2005  \n",
       "104002                                8.732624      3  2005  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Pipeline ##\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "\n",
    "## Preprocessing ##\n",
    "# Define features to include #\n",
    "pass_features = ['leaf_area_index_high_vegetation', 'slope_of_sub_gridscale_orography']\n",
    "categorical_features = ['type_of_high_vegetation']\n",
    "numeric_features = ['fire_count_past_3Days','fire_count_past_30Days','DMC','global_noon_LST_2m_temperature','BUI',\n",
    "                'FWI','latitude','FFMC','global_noon_LST_relative_humidity','24hr_max_temperature',\n",
    "                'global_noon_LST_2m_temperature_1dayLag','global_noon_LST_2m_temperature_2dayLag',\n",
    "                'high_vegetation_cover','24hr_max_temperature_1dayLag','low_vegetation_cover',\n",
    "                '24hr_accumulated_precipitation', 'day_of_the_year']\n",
    "####\n",
    "\n",
    "# Define custom preprocessing functions. Put any custom functions in SVM_functions.py also so they are accessible by the ensemble\n",
    "def extract_day_of_year(X):\n",
    "    day_of_year = X['date'].dt.dayofyear.to_frame(name='day_of_the_year')\n",
    "    return day_of_year\n",
    "\n",
    "# Define numeric and categorical transformer below\n",
    "date_transformer = ColumnTransformer([('date', FunctionTransformer(extract_day_of_year, validate=False), ['date'])], verbose_feature_names_out=False, remainder='passthrough').set_output(transform='pandas')\n",
    "scale=ColumnTransformer([('scale_transformer',StandardScaler(),numeric_features)],verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "cate=ColumnTransformer([('categorical_transformer',OneHotEncoder(sparse_output=False),categorical_features)],verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "pss=ColumnTransformer([('Pass_transformer','passthrough',pass_features)],verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "\n",
    "feature_union = FeatureUnion([\n",
    "    ('numeric', scale),\n",
    "    ('categorical', cate),\n",
    "    ('pass', pss)\n",
    "])\n",
    "\n",
    "\n",
    "# Final Pipeline\n",
    "Data_pipeline = Pipeline([\n",
    "    ('date_of_the_year', date_transformer),\n",
    "    ('feature_union', feature_union)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "X_train_processed = Data_pipeline.fit_transform(X_train)\n",
    "X_test_processed = Data_pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_lstm= np.resize(X_train_processed,(X_train_processed.shape[0],1,X_train_processed.shape[1]))\n",
    "X_test_lstm = np.resize(X_test_processed,(X_test_processed.shape[0],1,X_test_processed.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup LSTM model that is compatible for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input\n",
    "\n",
    "from keras_tuner.tuners import Hyperband\n",
    "import keras_tuner as kt\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.metrics import AUC\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def LSTM_classifier(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Define the input shape\n",
    "    model.add(Input(shape=(1, X_test_processed.shape[1])))\n",
    "\n",
    "    # Tune the number of LSTM layers\n",
    "    for i in range(1, 3):  # Adjust the range as needed\n",
    "        # Add LSTM layer with forget and memory gates\n",
    "        model.add(LSTM(units=hp.Int(f'units_{i}', min_value=X_test_processed.shape[1], max_value=X_test_processed.shape[1]*5, step=2),\n",
    "                       activation=hp.Choice(f'activation_{i}', ['relu', 'tanh', 'sigmoid', 'swish', 'linear']),\n",
    "                       recurrent_activation='sigmoid',  # Use sigmoid for forget and memory gates\n",
    "                       return_sequences=(i < 2)))  # Return sequences for all layers except the last one\n",
    "\n",
    "    # Tune whether to use dropout\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(Dropout(rate=0.20))\n",
    "\n",
    "    # Add the output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Define the optimizer learning rate as a hyperparameter\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperband tuning set up below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 51s]\n",
      "val_auc: 0.8486031591892242\n",
      "\n",
      "Best val_auc So Far: 0.8488591611385345\n",
      "Total elapsed time: 08h 38m 44s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(LSTM_classifier,\n",
    "                     objective=kt.Objective(\"val_auc\", direction=\"max\"),\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     executions_per_trial=2,\n",
    "                     overwrite=False,\n",
    "                     directory='LSTM_Hyperband_tuning',\n",
    "                     project_name='LSTM_R2')\n",
    "\n",
    "tuner.search(X_train_lstm, y_train, epochs=10, validation_data=(X_test_lstm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rxu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:435: UserWarning: Model 'sequential' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  model.build_from_config(\n",
      "c:\\Users\\rxu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - auc: 0.8603 - binary_accuracy: 0.8201 - loss: 0.4026 - val_auc: 0.8465 - val_binary_accuracy: 0.8673 - val_loss: 0.3202\n",
      "Epoch 2/5\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc: 0.8612 - binary_accuracy: 0.8201 - loss: 0.4024 - val_auc: 0.8465 - val_binary_accuracy: 0.8672 - val_loss: 0.3190\n",
      "Epoch 3/5\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - auc: 0.8646 - binary_accuracy: 0.8229 - loss: 0.3960 - val_auc: 0.8455 - val_binary_accuracy: 0.8675 - val_loss: 0.3196\n",
      "Epoch 4/5\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - auc: 0.8650 - binary_accuracy: 0.8209 - loss: 0.3980 - val_auc: 0.8437 - val_binary_accuracy: 0.8661 - val_loss: 0.3219\n",
      "Epoch 5/5\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - auc: 0.8599 - binary_accuracy: 0.8206 - loss: 0.4022 - val_auc: 0.8437 - val_binary_accuracy: 0.8666 - val_loss: 0.3243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_classifiers = tuner.get_best_models(num_models=1)\n",
    "best_classifier=best_classifiers[0]\n",
    "best_classifier.fit(x=X_train_lstm, y=y_train, batch_size=64, epochs=5, verbose=1, validation_split=0.2)\n",
    "best_classifier.save('LSTM_selected parameters_RX.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "F1 score on validation data: 0.6072922893006575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "#best_classifier.summary()\n",
    "X_validation_processed = Data_pipeline.transform(X_validation)\n",
    "X_validation_lstm= np.resize(X_validation_processed,(X_validation_processed.shape[0],1,X_validation_processed.shape[1]))\n",
    "\n",
    "# Assuming predictions is the output of best_classifier.predict(X_validation_processed)\n",
    "predictions = best_classifier.predict(X_validation_lstm)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "f1_score_result = f1_score(y_validation, binary_predictions)\n",
    "\n",
    "print('F1 score on validation data:', f1_score_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_df['month'] = validation_df['date'].dt.month\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_df['year'] = validation_df['date'].dt.year\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_train_df['month'] = test_train_df['date'].dt.month\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_train_df['year'] = test_train_df['date'].dt.year\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by='month', inplace=True,ascending=True)\n",
      "C:\\Users\\rxu\\AppData\\Local\\Temp\\ipykernel_28008\\100590291.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[df['month'] == month].sort_values(by='year', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def load_full_df():\n",
    "    main_df = pd.read_csv(\"D:/Shared drives/MECE 788 - Forest Fire Prediction/Git_final_deliverable_folder/Models/processed_wildfire_ERA5_FWI.csv\",index_col=0)\n",
    "    main_df['date'] = pd.to_datetime(main_df['date'])\n",
    "    main_df.rename(columns={'latitude_ERA5': 'latitude', 'longitude_ERA5': 'longitude'},inplace=True)\n",
    "    unnamed_cols = [col for col in main_df.columns if col.startswith('Unnamed:')]\n",
    "    main_df.drop(columns=unnamed_cols, inplace=True)\n",
    "    main_df['type_of_high_vegetation'] = main_df['type_of_high_vegetation'].astype(int)\n",
    "    main_df['type_of_low_vegetation'] = main_df['type_of_low_vegetation'].astype(int)\n",
    "    return main_df\n",
    "\n",
    "main_df = load_full_df()\n",
    "\n",
    "# Create the validation dataframe out of data after 2019\n",
    "validation_df = main_df[main_df['date'] > pd.Timestamp('2019-01-01')]\n",
    "test_train_df = main_df[main_df['date'] < pd.Timestamp('2019-01-01')]\n",
    "\n",
    "# Get the splits\n",
    "X1_train, X1_test, X1_validation, y1_train, y1_test, y1_validation = En_test_train_validation_split(validation_df, test_train_df)\n",
    "X1_train.reset_index(drop=True,inplace=True)\n",
    "X1_test.reset_index(drop=True,inplace=True)\n",
    "X1_validation.reset_index(drop=True,inplace=True)\n",
    "\n",
    "X1_validation_processed = Data_pipeline.transform(X1_validation)\n",
    "X1_validation_lstm= np.resize(X1_validation_processed,(X1_validation_processed.shape[0],1,X1_validation_processed.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5637/5637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 889us/step\n"
     ]
    }
   ],
   "source": [
    "# Use full dataset now\n",
    "\n",
    "# Assuming predictions is the output of best_classifier.predict(X_validation_processed)\n",
    "fulldf_predictions = best_classifier.predict(X1_validation_lstm)\n",
    "np.save('LSTM_pred_proba.npy',fulldf_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on validation data: 0.2027363184079602\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert predictions to binary labels (0 or 1)\n",
    "fulldf_predictions = (predictions > 0.8).astype(int)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "fulldf_f1_score_result = f1_score(y1_validation, fulldf_predictions)\n",
    "\n",
    "print('F1 score on validation data:', fulldf_f1_score_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.io.shapereader import Reader\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "def plot_roc_curve(y_true, probabilities, point_thresholds=None, point_tprs=None):\n",
    "    \"\"\"\n",
    "    Plots the ROC curve for given probabilities and marks points specified by thresholds or TPRs,\n",
    "    with legends indicating threshold values and corresponding TPR.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array): True binary labels.\n",
    "        probabilities (array): Probabilities of the positive class.\n",
    "        point_thresholds (list): List of thresholds for which points to mark on the ROC curve.\n",
    "        point_tprs (list): List of TPRs for which points to mark on the ROC curve.\n",
    "    \"\"\"\n",
    "    # Calculate ROC curve points\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "\n",
    "    # Collect legend information\n",
    "    legend_handles = [plt.Line2D([0], [0], color='darkorange', lw=2)]\n",
    "    legend_labels = [f'ROC curve (area = {roc_auc:.2f})']\n",
    "\n",
    "    # Handle point_thresholds\n",
    "    if point_thresholds is not None:\n",
    "        for thresh in point_thresholds:\n",
    "            idx = np.argmin(np.abs(thresholds - thresh))\n",
    "            plt.plot(fpr[idx], tpr[idx], 'ro')\n",
    "            plt.vlines(x=fpr[idx], ymin=0, ymax=tpr[idx], color='grey', linestyle='--')\n",
    "            plt.hlines(y=tpr[idx], xmin=0, xmax=fpr[idx], color='grey', linestyle='--')\n",
    "            print(f\"Threshold: {thresh:.8f}, TPR: {tpr[idx]:.4f}, FPR: {fpr[idx]:.4f}\")\n",
    "            legend_handles.append(plt.Line2D([0], [0], color='red', marker='o', linestyle=''))\n",
    "            legend_labels.append(f'Point (Thresh={thresh:.3f}, TPR={tpr[idx]:.3f})')\n",
    "\n",
    "    # Handle point_tprs\n",
    "    if point_tprs is not None:\n",
    "        for t in point_tprs:\n",
    "            idx = np.argmin(np.abs(tpr - t))\n",
    "            plt.plot(fpr[idx], tpr[idx], 'bo')\n",
    "            plt.vlines(x=fpr[idx], ymin=0, ymax=tpr[idx], color='grey', linestyle='--')\n",
    "            plt.hlines(y=tpr[idx], xmin=0, xmax=fpr[idx], color='grey', linestyle='--')\n",
    "            print(f\"Threshold: {thresholds[idx]:.8f}, TPR: {t:.4f}, FPR: {fpr[idx]:.4f}\")\n",
    "            legend_handles.append(plt.Line2D([0], [0], color='blue', marker='o', linestyle=''))\n",
    "            legend_labels.append(f'Point (Thresh={thresholds[idx]:.3f}, TPR={t:.3f})')\n",
    "\n",
    "    # Add legend to plot\n",
    "    plt.legend(legend_handles, legend_labels, loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiple_ROC(y_true, y_prediction_proba, names):\n",
    "    \"\"\"\n",
    "    Plot ROC curves for multiple predictions on the same plot.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: array-like of shape (n_samples,) - True binary labels.\n",
    "    - y_prediction_proba: list of array-like predictions from different models, \n",
    "                          each of shape (n_samples,).\n",
    "    - names: list of strings, names corresponding to each prediction in y_prediction_proba.\n",
    "    \n",
    "    Each element in y_prediction_proba corresponds to a prediction array from a model,\n",
    "    and each element in names is the name of the model used in the legend.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for y_pred, name in zip(y_prediction_proba, names):\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot the ROC curve\n",
    "        plt.plot(fpr, tpr, label=f'{name}: AUC = {roc_auc:.2f}')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Plot the diagonal 45 degree line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def get_cm(y_true, y_predict, save_path):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_predict)\n",
    "    \n",
    "    # Calculate the percentage of each value\n",
    "    cm_sum = np.sum(cm)\n",
    "    cm_percentage = cm / cm_sum * 100\n",
    "\n",
    "    # Create annotation labels\n",
    "    # Combine count and percentage in the annotation, formatted for display\n",
    "    annot_labels = (np.asarray([\"{}\\n({:.2f}%)\".format(count, percentage)\n",
    "                                for count, percentage in zip(cm.flatten(), cm_percentage.flatten())])\n",
    "                    .reshape(cm.shape))\n",
    "    \n",
    "    # Plotting the heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=annot_labels, fmt='', cmap='Blues', cbar=True)  # Using '' for fmt as we're passing strings in annot_labels\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()  # Close the plot to free memory if generating multiple plots\n",
    "\n",
    "## Functions for plotting predictions ##\n",
    "def add_back_original_features(X_processed,df_original):\n",
    "    \"\"\"\n",
    "    Adds removed features from the original dataframe back to a processed dataframe\n",
    "    \"\"\"\n",
    "    non_overlapping_columns = [col for col in df_original.columns if col not in X_processed.columns]\n",
    "    df_right_selected = df_original[non_overlapping_columns]\n",
    "    X_combined = pd.merge(X_processed, df_right_selected, left_index=True, right_index=True, how='left')\n",
    "    return X_combined\n",
    "\n",
    "def prepare_df_for_plotting(X,y_pred,df):\n",
    "    \"\"\"\n",
    "    X is the test inputs, y_pred is the resulting model predictions\n",
    "    df is the original dataframe to add back date, latitude, and longitude columns\n",
    "    \"\"\"\n",
    "    df = add_back_original_features(X,df)\n",
    "    df['prediction'] = y_pred\n",
    "    # Classify each prediction\n",
    "    df['result'] = 'TN'\n",
    "    df.loc[(df['fire'] == 1) & (df['prediction'] == 1), 'result'] = 'TP'\n",
    "    df.loc[(df['fire'] == 0) & (df['prediction'] == 1), 'result'] = 'FP'\n",
    "    df.loc[(df['fire'] == 1) & (df['prediction'] == 0), 'result'] = 'FN'\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_daily_predictions(df,save_dir):\n",
    "    \"\"\"\n",
    "    Plots and saves each plot as a png into save_dir.\n",
    "    Use prepare_df_for_plotting to get prediction column (true negative, true positive, etc.)\n",
    "    Parameters:\n",
    "        df = dataframe with a column that classifies prediction type (TN, TP, FP, FN)\n",
    "        save_dir = path to directory to save daily images\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    # Define the geographic bounds of Alberta\n",
    "    extent = [-120, -110, 49, 60]  # [west, east, south, north]\n",
    "    provinces = cfeature.NaturalEarthFeature(\n",
    "            category='cultural',\n",
    "            name='admin_1_states_provinces_lines',\n",
    "            scale='50m',\n",
    "            facecolor='none',\n",
    "            edgecolor='black'\n",
    "        )\n",
    "\n",
    "    for date in df['date'].unique():\n",
    "        df_date = df[df['date'] == date]\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        # Define the projection and extent\n",
    "        ax = plt.axes(projection=ccrs.LambertConformal(central_longitude=-115, central_latitude=55))\n",
    "        ax.set_extent(extent)\n",
    "        \n",
    "        # Add geographic features\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "        ax.add_feature(cfeature.LAND)\n",
    "        ax.add_feature(cfeature.COASTLINE)\n",
    "        ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "        ax.add_feature(provinces, linestyle='-', edgecolor='black')\n",
    "\n",
    "        # Plot points for the given date\n",
    "        categories = ['TP', 'TN', 'FP', 'FN']\n",
    "        colors = ['green', 'blue', 'red', 'yellow']\n",
    "        for category, color in zip(categories, colors):\n",
    "            df_cat = df_date[df_date['result'] == category]\n",
    "            plt.scatter(df_cat['longitude'], df_cat['latitude'], c=color, label=category, alpha=0.6, transform=ccrs.PlateCarree())\n",
    "        \n",
    "        plt.title(f'Fire Prediction Results for {date}')\n",
    "        plt.legend(loc='lower left')\n",
    "        \n",
    "        # Save the plot\n",
    "        plt.savefig(os.path.join(save_dir, f'{date}_predictions.png'))\n",
    "        plt.close(fig)\n",
    "\n",
    "def plot_incorrect_predictions(df, save_path):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of incorrect predictions over a dataset.\n",
    "    Use prepare_df_for_plotting to get prediction column (true negative, true positive, etc.)\n",
    "    Parameters:\n",
    "        df = dataframe with prediction column that classifies prediction type (TP, TN, FP, FN)\n",
    "        save_path = path to save the heatmap image\n",
    "    \"\"\"\n",
    "    # Create a DataFrame of all unique latitude and longitude pairs with zero counts\n",
    "    all_coords = df[['latitude', 'longitude']].drop_duplicates()\n",
    "    all_coords['counts'] = 0\n",
    "\n",
    "    # Filter to include only incorrect predictions\n",
    "    incorrect_df = df[(df['result'] == 'FP') | (df['result'] == 'FN')]\n",
    "    incorrect_counts = incorrect_df.groupby(['latitude', 'longitude']).size().reset_index(name='counts_fn')\n",
    "\n",
    "    # Merge the counts back to all coordinates\n",
    "    agg_df = all_coords.merge(incorrect_counts, on=['latitude', 'longitude'], how='left')\n",
    "    agg_df['counts'] = agg_df['counts_fn'].fillna(0) + agg_df['counts']\n",
    "    agg_df.drop(columns=['counts_fn'], inplace=True)\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(40, 40))\n",
    "    ax = plt.axes(projection=ccrs.LambertConformal(central_longitude=-115, central_latitude=55))\n",
    "    ax.set_extent([-120, -110, 49, 60])\n",
    "\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "    ax.add_feature(cfeature.NaturalEarthFeature(category='cultural', name='admin_1_states_provinces_lines', scale='50m', facecolor='none', edgecolor='black'), linestyle='-')\n",
    "\n",
    "    norm = plt.Normalize(vmin=agg_df['counts'].min(), vmax=agg_df['counts'].max())\n",
    "    scatter = ax.scatter(agg_df['longitude'], agg_df['latitude'], c=agg_df['counts'], cmap='Reds', norm=norm, edgecolor='k', linewidth=0.5, alpha=0.7, s=600, transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(scatter, shrink=0.5, aspect=5)\n",
    "    cbar.set_label('Number of Incorrect Predictions', fontsize=40)\n",
    "    cbar.ax.tick_params(labelsize=30)\n",
    "\n",
    "    plt.title('Incorrect Predictions Across Alberta', fontsize=40)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_false_positives(df, save_path):\n",
    "    \"\"\"\n",
    "    Same as plot_incorrect_predictions except plots false positives rather than incorrect predictions\n",
    "    Plots a heatmap of incorrect predictions over a dataset.\n",
    "    Use prepare_df_for_plotting to get prediction column (true negative, true positive, etc.)\n",
    "    Parameters:\n",
    "        df = dataframe with prediction column that classifies prediction type (TP, TN, FP, FN)\n",
    "        save_path = path to save the heatmap image\n",
    "    \"\"\"\n",
    "    # Create a DataFrame of all unique latitude and longitude pairs with zero counts\n",
    "    all_coords = df[['latitude', 'longitude']].drop_duplicates()\n",
    "    all_coords['counts'] = 0\n",
    "\n",
    "    # Filter to include only false positive predictions\n",
    "    fp_df = df[df['result'] == 'FP']\n",
    "    fp_counts = fp_df.groupby(['latitude', 'longitude']).size().reset_index(name='counts_fn')\n",
    "\n",
    "    # Merge the counts back to all coordinates\n",
    "    agg_df = all_coords.merge(fp_counts, on=['latitude', 'longitude'], how='left')\n",
    "    agg_df['counts'] = agg_df['counts_fn'].fillna(0) + agg_df['counts']\n",
    "    agg_df.drop(columns=['counts_fn'], inplace=True)\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(40, 40))\n",
    "    ax = plt.axes(projection=ccrs.LambertConformal(central_longitude=-115, central_latitude=55))\n",
    "    ax.set_extent([-120, -110, 49, 60])  # Geographic bounds for Alberta\n",
    "\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "    ax.add_feature(cfeature.NaturalEarthFeature(category='cultural', name='admin_1_states_provinces_lines', scale='50m', facecolor='none', edgecolor='black'), linestyle='-')\n",
    "\n",
    "    norm = plt.Normalize(vmin=agg_df['counts'].min(), vmax=agg_df['counts'].max())\n",
    "    scatter = ax.scatter(agg_df['longitude'], agg_df['latitude'], c=agg_df['counts'], cmap='Reds', norm=norm, edgecolor='k', linewidth=0.5, alpha=0.7, s=600, transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(scatter, shrink=0.5, aspect=5)\n",
    "    cbar.set_label('Number of False Positives', fontsize=40)\n",
    "    cbar.ax.tick_params(labelsize=30)\n",
    "\n",
    "    plt.title('False Positive Predictions Across Alberta', fontsize=40)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_false_negatives(df, save_path):\n",
    "    \"\"\"\n",
    "    Variant of plot_incorrect_predictions for looking at false negatives specifically.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame of all unique latitude and longitude pairs\n",
    "    all_coords = df[['latitude', 'longitude']].drop_duplicates()\n",
    "    all_coords['counts'] = 0  # Initialize counts to zero\n",
    "\n",
    "    # Filter to include only false negative predictions\n",
    "    fn_df = df[df['result'] == 'FN']\n",
    "\n",
    "    # Group by latitude and longitude, count occurrences\n",
    "    fn_counts = fn_df.groupby(['latitude', 'longitude']).size().reset_index(name='counts')\n",
    "\n",
    "    # Merge the counts back to all coordinates\n",
    "    agg_df = all_coords.merge(fn_counts, on=['latitude', 'longitude'], how='left', suffixes=('', '_fn'))\n",
    "    agg_df['counts'] = agg_df['counts_fn'].fillna(0) + agg_df['counts']\n",
    "    agg_df.drop(columns=['counts_fn'], inplace=True)\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(40, 40))\n",
    "    ax = plt.axes(projection=ccrs.LambertConformal(central_longitude=-115, central_latitude=55))\n",
    "    ax.set_extent([-120, -110, 49, 60])  # Geographic bounds for Alberta\n",
    "\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "    ax.add_feature(cfeature.NaturalEarthFeature(category='cultural', name='admin_1_states_provinces_lines', scale='50m', facecolor='none', edgecolor='black'), linestyle='-')\n",
    "\n",
    "    norm = plt.Normalize(vmin=agg_df['counts'].min(), vmax=agg_df['counts'].max())\n",
    "    scatter = ax.scatter(agg_df['longitude'], agg_df['latitude'], c=agg_df['counts'], cmap='Blues', norm=norm, edgecolor='k', linewidth=0.5, alpha=0.7, s=600, transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(scatter, shrink=0.5, aspect=5)\n",
    "    cbar.set_label('Number of False Negatives', fontsize=40)\n",
    "    cbar.ax.tick_params(labelsize=30)\n",
    "\n",
    "    plt.title('False Negative Predictions Across Alberta', fontsize=40)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "## High Level Function for getting all visualizations ##\n",
    "def generate_visualizations(X_processed,y_predict,y_true,df_original,save_path):\n",
    "    \"\"\"\n",
    "    Generates visualizations for model predictions\n",
    "    \"\"\"\n",
    "    os.makedirs(save_path,exist_ok=True)\n",
    "    # Add features back to prediction dataset\n",
    "    df = prepare_df_for_plotting(X_processed,y_predict,df_original)\n",
    "    \n",
    "    # Prepare and save plots\n",
    "    get_cm(y_true,y_predict,os.path.join(save_path,'cm.png'))\n",
    "    plot_incorrect_predictions(df, os.path.join(save_path,'incorrect_predictions.png'))\n",
    "    plot_false_positives(df, os.path.join(save_path,'false_positives.png'))\n",
    "    plot_false_negatives(df, os.path.join(save_path,'false_negatives.png'))\n",
    "    #plot_daily_predictions(df,os.path.join(save_path,'validation_predictions'))\n",
    "\n",
    "\n",
    "generate_visualizations(X1_validation,fulldf_predictions,y1_validation,main_df,'D:/Shared drives/MECE 788 - Forest Fire Prediction/05_Analysis/02_LSTM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
