{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YKnxyxvjGoya"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "    Version 2.0 - Support Vector Classifier\n",
    "    Data Source: European Space Agency - ERA5\n",
    "                 Government of Alberta - Historical Wildfire registry and Fire Weather Indices\n",
    "                 Natural Resources Canada - Vegetation Classification of Canada\n",
    "'''\n",
    "# General imports\n",
    "import pandas as pd\n",
    "\n",
    "# SVM specific functions\n",
    "from SVM_functions import SVM_test_train_validation_split, SVM_pipeline\n",
    "\n",
    "# Other imports appear where needed. Specifically, imports joblib and parts of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y8xYsDLmGoyb"
   },
   "outputs": [],
   "source": [
    "## Test, Train, Validation Splits ##\n",
    "\n",
    "# Load wildfire dataframe and convert date column to datetime\n",
    "main_df = pd.read_csv(\"downsampled_df.csv\",index_col=0)\n",
    "main_df['date'] = pd.to_datetime(main_df['date'])\n",
    "\n",
    "# Create training and validations dataframes\n",
    "validation_df = main_df[main_df['date'] > pd.Timestamp('2019-01-01')]\n",
    "test_train_df = main_df[main_df['date'] < pd.Timestamp('2019-01-01')]\n",
    "\n",
    "# Get splits\n",
    "X_train, X_test, X_validation, y_train, y_test, y_validation = SVM_test_train_validation_split(validation_df,test_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "w0I8B-Q8Goyd"
   },
   "outputs": [],
   "source": [
    "## Pipeline ##\n",
    "\n",
    "pass_features = [ 'leaf_area_index_high_vegetation']\n",
    "categorical_features = []\n",
    "numeric_features = ['fire_count_past_3Days', 'global_noon_LST_2m_temperature', 'FFMC', 'DMC', 'FWI', 'BUI', 'global_noon_LST_relative_humidity', '24hr_max_temperature']\n",
    "Data_pipeline = SVM_pipeline(pass_features,categorical_features,numeric_features)\n",
    "\n",
    "# Prepare the train and test data\n",
    "X_train_processed=Data_pipeline.fit_transform(X_train)\n",
    "X_test_processed=Data_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n",
      "Best parameters: {'C': 10, 'gamma': 0.1}\n",
      "F1 Score: 74.14%\n"
     ]
    }
   ],
   "source": [
    "## Grid Search for Current Model ##\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#F1 scorer\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "\n",
    "# Parameters\n",
    "p_grid = {\"C\": [6, 8, 10],\n",
    "          \"gamma\": ['scale', 0.01, 0.1]\n",
    "}\n",
    "\n",
    "sv_classifier = SVC(kernel=\"rbf\",random_state=42)\n",
    "grid_search = GridSearchCV(sv_classifier, p_grid, cv=4, scoring=f1,n_jobs=-1,verbose=1)\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(f\"F1 Score: {100*grid_search.best_score_:.2f}%\")\n",
    "\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fitting 4 folds for each of 9 candidates, totalling 36 fits\n",
    "# Best parameters: {'C': 10, 'gamma': 0.1}\n",
    "# F1 Score: 74.14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc_model_reduced_features_V1.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save the model ##\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_classifier, 'svc_model_reduced_features_V1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8ASg4mO9Goyg",
    "outputId": "0ab96d82-f096-48eb-f3fd-a344dc6da1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy: 0.8240497250776955\n",
      "f1 score:  0.6003800732998507\n"
     ]
    }
   ],
   "source": [
    "## Performance on Validation Set ##\n",
    "\n",
    "# Predict on the validation set\n",
    "y_test_pred = best_classifier.predict(X_test_processed)\n",
    "\n",
    "# Evaluate the accuracy of the model on the validation set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Validation set accuracy:\", accuracy)\n",
    "print('f1 score: ',f1_score(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
