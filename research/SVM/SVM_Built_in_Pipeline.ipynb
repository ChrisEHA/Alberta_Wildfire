{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJ26prR0GoyZ"
   },
   "source": [
    "This is the code for random forest training by Raymond Xu.\n",
    "\n",
    " In this edition, the longitude and latitude of the original wildfire dataset is used as inputs.\n",
    "\n",
    " Here the temporal sequence is not considered in the data splitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YKnxyxvjGoya"
   },
   "outputs": [],
   "source": [
    "''' This is Research Project titled ML Algorithms for Alberta Forest Occurence Prediction.\n",
    "    This is the 8th Engineering Research Project, and is hereby delcared as\n",
    "\n",
    "                            Project Christopher\n",
    "\n",
    "    Version 2.0 - Random Forest Classifier\n",
    "    Data Source: European Space Agency - ERA5\n",
    "                 Government of Alberta - Historical Wildfire registry and Fire Weather Indices\n",
    "                 Natural Resources Canada - Vegetation Classification of Canada\n",
    "\n",
    "    AI Diederik - Hongik Ingan, For the Benefits of All Mankind\n",
    "'''\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder,LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif,chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "set_config(transform_output = \"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y8xYsDLmGoyb"
   },
   "outputs": [],
   "source": [
    "# Load wildfire and non-wildfire datasets\n",
    "main_df = pd.read_csv(\"downsampled_df.csv\",index_col=0)\n",
    "\n",
    "# Remove the first unnamed column\n",
    "wf_df=main_df[main_df['fire']==1]\n",
    "nwf_df=main_df[main_df['fire']==0]\n",
    "\n",
    "# Define Split ratio, aka percentage of the combined data goes to training\n",
    "split=[0.6,0.2,0.2]\n",
    "wf_sort = wf_df.sort_values(by='date')\n",
    "nwf_sort = nwf_df.sort_values(by='date')\n",
    "\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    wf_memory=0\n",
    "    nfw_memory=0\n",
    "    wf_selected=[]\n",
    "    nwf_selected=[]\n",
    "    wf_size = int(split[i] * len(wf_df))\n",
    "    nwf_size = int(split[i] * len(nwf_df))\n",
    "    if i==0:\n",
    "        wf_selected=wf_sort[:wf_size]\n",
    "        nwf_selected=nwf_sort[:nwf_size]\n",
    "        wf_memory=wf_size\n",
    "        nwf_memory=nwf_size\n",
    "        train_data = pd.concat([wf_selected, nwf_selected])\n",
    "    if i==1:\n",
    "        wf_selected=wf_sort[wf_memory:wf_memory+wf_size]\n",
    "        nwf_selected=nwf_sort[nwf_memory:nwf_memory+nwf_size]\n",
    "        wf_memory=wf_size\n",
    "        nwf_memory=nwf_size\n",
    "        test_data = pd.concat([wf_selected, nwf_selected])\n",
    "    if i==2:\n",
    "        wf_selected=wf_sort[wf_memory:]\n",
    "        nwf_selected=nwf_sort[nwf_memory:]\n",
    "        val_data = pd.concat([wf_selected, nwf_selected])\n",
    "\n",
    "X_train = train_data.drop(columns={'fire','date'})\n",
    "X_test = test_data.drop(columns={'fire','date'})\n",
    "X_val = val_data.drop(columns={'fire','date'})\n",
    "y_train = train_data['fire']\n",
    "y_test = test_data['fire']\n",
    "y_val = val_data['fire']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2RWITk9Goyc"
   },
   "source": [
    "Set up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w0I8B-Q8Goyd"
   },
   "outputs": [],
   "source": [
    "# Manual separate numerical and categorical columns\n",
    "\n",
    "# Select variables\n",
    "#pass_features = [ 'leaf_area_index_high_vegetation']\n",
    "#categorical_features = []\n",
    "#numeric_features = ['fire_count_past_3Days', 'global_noon_LST_2m_temperature', 'FFMC', 'DMC', 'FWI', 'BUI', 'global_noon_LST_relative_humidity', '24hr_max_temperature']\n",
    "\n",
    "# Almost all variables\n",
    "pass_features = [ 'leaf_area_index_high_vegetation','slope_of_sub_gridscale_orography']\n",
    "categorical_features = ['type_of_high_vegetation','type_of_low_vegetation']\n",
    "numeric_features = ['high_vegetation_cover',\n",
    "       'low_vegetation_cover', \n",
    "       '24hr_accumulated_precipitation', \n",
    "       '24hr_max_temperature',\n",
    "       'global_noon_LST_2m_temperature', \n",
    "       'global_noon_LST_relative_humidity',\n",
    "       'global_noon_LST_wind_speed', \n",
    "       'BUI', \n",
    "       'DC', \n",
    "       'DMC', \n",
    "       'FFMC', \n",
    "       'FWI',\n",
    "       'fire_count_past_3Days', \n",
    "       'fire_count_past_30Days',\n",
    "       '24hr_max_temperature_1dayLag', \n",
    "       '24hr_max_temperature_2dayLag',\n",
    "       'global_noon_LST_2m_temperature_1dayLag',\n",
    "       'global_noon_LST_2m_temperature_2dayLag']\n",
    "\n",
    "# Define numeric and categorical transformer below\n",
    "scale=ColumnTransformer([('scale_transformer',StandardScaler(),numeric_features)],verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "\n",
    "cate=ColumnTransformer([('categorical_transformer',OneHotEncoder(sparse_output=False),categorical_features)],verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "\n",
    "pss=ColumnTransformer([('Pass_transformer','passthrough',pass_features)],verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "\n",
    "Data_pipeline = Pipeline(steps=[\n",
    "    ('Feature Union',FeatureUnion([('numeric', scale),('categorical',cate),('pass',pss)])),\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "b18aBChNQwgW"
   },
   "outputs": [],
   "source": [
    "X_train_processed=Data_pipeline.fit_transform(X_train)\n",
    "X_test_processed=Data_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a17dUTYpRD3u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'longitude', 'high_vegetation_cover',\n",
       "       'leaf_area_index_high_vegetation', 'leaf_area_index_low_vegetation',\n",
       "       'low_vegetation_cover', 'slope_of_sub_gridscale_orography',\n",
       "       'type_of_high_vegetation', 'type_of_low_vegetation',\n",
       "       '24hr_accumulated_precipitation', '24hr_max_temperature',\n",
       "       'global_noon_LST_2m_temperature', 'global_noon_LST_relative_humidity',\n",
       "       'global_noon_LST_wind_speed', 'BUI', 'DC', 'DMC', 'FFMC', 'FWI',\n",
       "       'fire_count_past_3Days', 'fire_count_past_7Days',\n",
       "       'fire_count_past_10Days', 'fire_count_past_30Days',\n",
       "       '24hr_max_temperature_1dayLag', '24hr_max_temperature_2dayLag',\n",
       "       'global_noon_LST_2m_temperature_1dayLag',\n",
       "       'global_noon_LST_2m_temperature_2dayLag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters: {'C': 10}\n",
      "F1 Score: 74.60%\n"
     ]
    }
   ],
   "source": [
    "# nested cross-validation\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "\n",
    "#F1 scorer\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "\n",
    "p_grid = {\"C\": [1, 10, 100]} #\"gamma\": [0.01, 0.1]\n",
    "\n",
    "\n",
    "sv_classifier = SVC(kernel=\"rbf\",random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(sv_classifier, p_grid, cv=5, scoring=f1,n_jobs=-1,verbose=1)\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(f\"F1 Score: {100*grid_search.best_score_:.2f}%\")\n",
    "\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# For the feature space:\n",
    "# pass_features = [ 'leaf_area_index_high_vegetation']\n",
    "# categorical_features = []\n",
    "# numeric_features = ['fire_count_past_3Days', 'global_noon_LST_2m_temperature', 'FFMC', 'DMC', 'FWI', 'BUI', 'global_noon_LST_relative_humidity', '24hr_max_temperature']\n",
    "# Best params are:\n",
    "# Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
    "# Best parameters: {'C': 10}\n",
    "# F1 Score: 74.12%\n",
    "\n",
    "# For a (nearly) full feature space:\n",
    "# Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
    "# Best parameters: {'C': 10}\n",
    "# F1 Score: 74.60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best parameters: {'C': 8, 'gamma': 'scale'}\n",
      "F1 Score: 74.56%\n"
     ]
    }
   ],
   "source": [
    "# nested cross-validation\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "#F1 scorer\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "\n",
    "p_grid = {\"C\": [8, 10],\n",
    "          \"gamma\": ['scale', 0.01, 0.1]\n",
    "}\n",
    "\n",
    "sv_classifier = SVC(kernel=\"rbf\",random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(sv_classifier, p_grid, cv=4, scoring=f1,n_jobs=-1,verbose=1)\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(f\"F1 Score: {100*grid_search.best_score_:.2f}%\")\n",
    "\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# For the nearly full parameter space\n",
    "# Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
    "# Best parameters: {'C': 8, 'gamma': 'scale'}\n",
    "# F1 Score: 74.56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc_model_cv_V1.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_classifier, 'svc_model_cv_V1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8ASg4mO9Goyg",
    "outputId": "0ab96d82-f096-48eb-f3fd-a344dc6da1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy: 0.8264626717665392\n",
      "f1 score:  0.6021435531016563\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "y_test_pred = best_classifier.predict(X_test_processed)\n",
    "\n",
    "# Evaluate the accuracy of the model on the validation set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Validation set accuracy:\", accuracy)\n",
    "print('f1 score: ',f1_score(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
